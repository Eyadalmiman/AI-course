{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d033998",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7728386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import simplejson\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403a227",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb701611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'AI Assistant', 'Version': 1.0, 'Features': ['chat', 'translate', 'summarize'], 'Active': True}\n",
      "Name: AI Assistant\n",
      "Version: 1.0\n",
      "Features: ['chat', 'translate', 'summarize']\n",
      "Active: True\n"
     ]
    }
   ],
   "source": [
    "with open(\"config1.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(config)\n",
    "print(\"Name:\", config[\"Name\"])\n",
    "print(\"Version:\", config[\"Version\"])\n",
    "print(\"Features:\", config[\"Features\"])\n",
    "print(\"Active:\", config[\"Active\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76e9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "configtest = {\n",
    "    \"architecture\": \"resnet18\",\n",
    "    \"input_dim\": 224,\n",
    "    \"num_classes\": 10,\n",
    "    \"omptimizer\": {\n",
    "        \"type\": \"adam\",\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 1e-4\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 20\n",
    "    }\n",
    "}\n",
    "with open(\"configtest.json\", \"w\") as f:\n",
    "    json.dump(configtest, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e062cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': 'resnet18',\n",
       " 'input_dim': 224,\n",
       " 'num_classes': 10,\n",
       " 'omptimizer': {'type': 'adam', 'lr': 0.001, 'weight_decay': 0.0001},\n",
       " 'training': {'batch_size': 64, 'epochs': 20}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"configtest.json\", \"r\") as f:\n",
    "    congitest = json.load(f)\n",
    "configtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e257cee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    10,\n",
      "    20,\n",
      "    30\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent = 4, sort_keys = True)) # Pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 20 epochs...\n",
      "Results saved!\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Configuration\n",
    "with open(\"config1.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Safely get number of epochs from possible locations, with sensible fallbacks\n",
    "epochs = None\n",
    "if isinstance(config, dict):\n",
    "    epochs = config.get(\"epochs\")\n",
    "    if epochs is None:\n",
    "        # support nested config like {\"training\": {\"epochs\": 20}}\n",
    "        epochs = config.get(\"training\", {}).get(\"epochs\")\n",
    "\n",
    "# fallback to configtest (if present in the notebook) or a default value\n",
    "if epochs is None:\n",
    "    if \"configtest\" in globals() and isinstance(globals().get(\"configtest\"), dict):\n",
    "        epochs = globals()[\"configtest\"].get(\"training\", {}).get(\"epochs\")\n",
    "if epochs is None:\n",
    "    epochs = 10  # default\n",
    "\n",
    "print(f\"Training with {epochs} epochs...\")\n",
    "\n",
    "# 2.Training Process (simplified)\n",
    "results = {\"accuracy\": 0.95, \"loss\": 0.04}\n",
    "\n",
    "# 3. Save Results\n",
    "try:\n",
    "    with open(\"results1.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent = 4)\n",
    "    print(\"Results saved!\")\n",
    "except IOError as e:\n",
    "    print(f\"Failed to save: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb09a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: {'mean': 3.0, 'max': 5, 'min': 1}\n",
      "B: {'mean': 20.0, 'max': 30, 'min': 10}\n"
     ]
    }
   ],
   "source": [
    "# from typing import List, Dict\n",
    "cat_a = [1, 2, 3, 4, 5]\n",
    "cat_b = [10, 20, 30]\n",
    "\n",
    "def calculate_stats(data:list[float])->dict[str, float]:\n",
    "    mean = sum(data) / len(data)\n",
    "    max_number = max(data)\n",
    "    min_number = min(data)\n",
    "    results = {\"mean\" : mean,\n",
    "               \"max\" : max_number,\n",
    "               \"min\" : min_number}\n",
    "    return results\n",
    "\n",
    "stats_a = calculate_stats(cat_a)\n",
    "stats_b = calculate_stats(cat_b)\n",
    "\n",
    "print(\"A:\", stats_a)\n",
    "print(\"B:\", stats_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8bd9704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics: {'mean': 20.0, 'max': 30, 'min': 10}\n",
      "normalized & standardized: {'minmax': [0.0, 0.5, 1.0], 'zscore': [-1.224744871391589, 0.0, 1.224744871391589]}\n"
     ]
    }
   ],
   "source": [
    "# from typing import List, Dict, Tuple\n",
    "# import pandas as pd\n",
    "data = [10, 20, 30]\n",
    "\n",
    "def calculate_statistics(data: list[float]) -> dict[str, float]:\n",
    "    if not data:\n",
    "        return {\"mean\": 0.0, \"max\": 0.0, \"min\": 0.0}\n",
    "    mean = sum(data) / len(data)\n",
    "    max_number = max(data)\n",
    "    min_number = min(data)\n",
    "    results = {\"mean\": mean,\n",
    "               \"max\": max_number,\n",
    "               \"min\": min_number}\n",
    "    return results\n",
    "\n",
    "def normalize_data(data: list[float], method: str = \"both\") -> dict[str, list[float]]:\n",
    "    \"\"\"\n",
    "    method: 'minmax', 'zscore', or 'both'\n",
    "    Returns dict with requested normalized arrays as Python lists.\n",
    "    \"\"\"\n",
    "    import numpy as np  # safe: numpy already imported elsewhere, this won't duplicate in other cells\n",
    "    arr = np.array(data, dtype=float)\n",
    "    res: dict[str, list[float]] = {}\n",
    "\n",
    "    if method in (\"minmax\", \"both\"):\n",
    "        min_val = arr.min()\n",
    "        max_val = arr.max()\n",
    "        denom = max_val - min_val\n",
    "        if denom == 0:\n",
    "            minmax = np.zeros_like(arr)\n",
    "        else:\n",
    "            minmax = (arr - min_val) / denom\n",
    "        res[\"minmax\"] = minmax.tolist()\n",
    "\n",
    "    if method in (\"zscore\", \"both\"):\n",
    "        mean = arr.mean()\n",
    "        std = arr.std()\n",
    "        if std == 0:\n",
    "            zscore = np.zeros_like(arr)\n",
    "        else:\n",
    "            zscore = (arr - mean) / std\n",
    "        res[\"zscore\"] = zscore.tolist()\n",
    "\n",
    "    return res\n",
    "\n",
    "def train_test_split(data: list[float], ratio: float = 0.8) -> tuple[list[float], list[float]]:\n",
    "    split = int(len(data) * ratio)\n",
    "    return data[:split], data[split:]\n",
    "\n",
    "def encode_labels(labels: list) -> tuple[list[int], dict]:\n",
    "    unique = []\n",
    "    mapping = {}\n",
    "    for lbl in labels:\n",
    "        if lbl not in mapping:\n",
    "            mapping[lbl] = len(mapping)\n",
    "            unique.append(lbl)\n",
    "    encoded = [mapping[l] for l in labels]\n",
    "    return encoded, mapping\n",
    "\n",
    "statistics = calculate_statistics(data)\n",
    "nor_stan = normalize_data(data, method=\"both\")\n",
    "print(\"statistics:\", statistics)\n",
    "print(\"normalized & standardized:\", nor_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90269bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product    price  quantity     total category\n",
      "0  Widget A  1234.50      10.0  12345.00      med\n",
      "1  Widget B   567.89       5.0   2839.45      low\n",
      "2  Widget C  2345.00       0.0      0.00     high\n"
     ]
    }
   ],
   "source": [
    "raw = {\n",
    "   \"product\": [\"Widget A\", \"Widget B\", \"Widget C\"],\n",
    "   \"price\": [\"$1,234.50\", \"$567.89\", \"$2,345.00\"],\n",
    "   \"quantity\": [10, 5, None],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "raw = {\n",
    "   \"product\": [\"Widget A\", \"Widget B\", \"Widget C\"],\n",
    "   \"price\": [\"$1,234.50\", \"$567.89\", \"$2,345.00\"],\n",
    "   \"quantity\": [10, 5, None],\n",
    "}\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "df['price'] = df['price'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "\n",
    "df['quantity'] = df['quantity'].apply(lambda x: 0 if pd.isna(x) else x)\n",
    "df['total'] = df.apply(lambda row: row['price'] * row['quantity'], axis=1)\n",
    "\n",
    "def categorize(p):\n",
    "    if p < 600:\n",
    "        return 'low'\n",
    "    elif p <= 1500:\n",
    "        return 'med'\n",
    "    else: return 'high'\n",
    "\n",
    "df['category'] = df['price'].apply(lambda x: categorize(x))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5238e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product    price  quantity     total category\n",
      "0  Widget A  1234.50      10.0  12345.00      med\n",
      "1  Widget B   567.89       5.0   2839.45      low\n",
      "2  Widget C  2345.00       0.0      0.00     high\n"
     ]
    }
   ],
   "source": [
    "raw = {\n",
    "   \"product\": [\"Widget A\", \"Widget B\", \"Widget C\"],\n",
    "   \"price\": [\"$1,234.50\", \"$567.89\", \"$2,345.00\"],\n",
    "   \"quantity\": [10, 5, None],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "raw = {\n",
    "   \"product\": [\"Widget A\", \"Widget B\", \"Widget C\"],\n",
    "   \"price\": [\"$1,234.50\", \"$567.89\", \"$2,345.00\"],\n",
    "   \"quantity\": [10, 5, None],\n",
    "}\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "df['price'] = df['price'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "\n",
    "df['quantity'] = df['quantity'].apply(lambda x: 0 if pd.isna(x) else x)\n",
    "df['total'] = df.apply(lambda row: row['price'] * row['quantity'], axis=1)\n",
    "\n",
    "def categorize(p):\n",
    "    if p < 600:\n",
    "        return 'low'\n",
    "    elif p <= 1500:\n",
    "        return 'med'\n",
    "    else: return 'high'\n",
    "\n",
    "df['category'] = df['price'].apply(lambda x: categorize(x))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecc55781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- before training --------------\n",
      "Experiment Name: student_score_model\n",
      "Model Name: SimpleScorePredictor\n",
      "Epochs: 5\n",
      "Learning Rate: 0.01\n",
      "Dataset Size: 150\n",
      "Epoch 1 : accuracy = 0.58, loss = 0.88\n",
      "Epoch 2 : accuracy = 0.66, loss = 0.76\n",
      "Epoch 3 : accuracy = 0.74, loss = 0.64\n",
      "Epoch 4 : accuracy = 0.82, loss = 0.52\n",
      "Epoch 5 : accuracy = 0.90, loss = 0.40\n",
      "----------------------------\n",
      "Results saved to results.json\n"
     ]
    }
   ],
   "source": [
    "# Activity\n",
    "# import json\n",
    "# from pathlib import path\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "def training(config):\n",
    "    accuracy = 0.5\n",
    "    loss = 1.0\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        accuracy += 0.08\n",
    "        loss -= 0.12\n",
    "        print(f\"Epoch {epoch} : accuracy = {accuracy:.2f}, loss = {loss:.2f}\")\n",
    "    \n",
    "    results = {\n",
    "        \"experiment_name\" : config[\"experiment_name\"],\n",
    "        \"model_name\" : config[\"model_name\"],\n",
    "        \"epochs\" : epochs,\n",
    "        \"accuracy\" : round(accuracy, 2),\n",
    "        \"loss\" : round(loss, 2),\n",
    "        \"finished\" : True\n",
    "        }\n",
    "    \n",
    "    print(\"----------------------------\")\n",
    "    return results\n",
    "\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent = 4)\n",
    "\n",
    "# prints\n",
    "print(\"-------------- before training --------------\")\n",
    "print(\"Experiment Name:\", config[\"experiment_name\"])\n",
    "print(\"Model Name:\", config[\"model_name\"])\n",
    "print(\"Epochs:\", config[\"epochs\"])\n",
    "print(\"Learning Rate:\", config[\"learning_rate\"])\n",
    "print(\"Dataset Size:\", config[\"dataset_size\"])\n",
    "results = training(config)\n",
    "print(\"Results saved to results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a69d8",
   "metadata": {},
   "source": [
    "__________________________\n",
    "Day 5 Activity: JSON + File Handling mini workflow.\n",
    "Tasks:\n",
    "1) Load training config from JSON\n",
    "2) Simulate training results (dict)\n",
    "3) Save results to JSON safely\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# TODO: Load config.json from disk\n",
    "# TODO: Print config values\n",
    "# TODO: Create results dict and write to results.json\n",
    "\n",
    "# Hint: use Path and with open(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
