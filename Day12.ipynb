{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86bfa4d0",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485a212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import simplejson\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c4eba",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476b2bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    raw_city city_clean_basic\n",
      "0   new york         new york\n",
      "1  New york          new york\n",
      "2   NEW YORK         new york\n",
      "3        nyc              nyc\n",
      "4        NYC              nyc\n"
     ]
    }
   ],
   "source": [
    "# Raw data\n",
    "df12 = pd.DataFrame({\n",
    "    \"raw_city\": [\" new york\", \"New york \", \"NEW YORK\", \"nyc\", \"NYC\"]\n",
    "})\n",
    "\n",
    "# Basic cleaning\n",
    "df12[\"city_clean_basic\"] = (\n",
    "    df12[\"raw_city\"]\n",
    "        .str.strip()      # remove leading/trailing spaces\n",
    "        .str.lower()      # lowercase\n",
    ")\n",
    "\n",
    "print(df12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f8e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    raw_city city_clean_sep\n",
      "0   new york       new york\n",
      "1  New york        new york\n",
      "2   NEW YORK       new york\n",
      "3        nyc            nyc\n",
      "4        NYC            nyc\n"
     ]
    }
   ],
   "source": [
    "df12 = pd.DataFrame({\"raw_city\": [\" new york\", \"New york \", \"NEW YORK\", \"nyc\", \"NYC\"]})\n",
    "\n",
    "df12[\"city_clean_sep\"] = (\n",
    "    df12[\"raw_city\"]\n",
    "        .str.lower()\n",
    "        .str.replace(\"-\", \" \", regex=False)\n",
    "        .str.replace(r\"[^a-z\\s]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    ")\n",
    "\n",
    "print(df12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb6e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    raw_city city_clean_basic city_clean_sep city_token city_canonical\n",
      "0   new york         new york       new york    newyork       new york\n",
      "1  New york          new york       new york    newyork       new york\n",
      "2   NEW YORK         new york       new york    newyork       new york\n",
      "3        nyc              nyc            nyc        nyc       new york\n",
      "4        NYC              nyc            nyc        nyc       new york\n"
     ]
    }
   ],
   "source": [
    "# Canonical city mapping\n",
    "canonical_map = {\n",
    "    \"new york\": \"new york\",\n",
    "    \"nyc\": \"new york\",\n",
    "    \"ny\": \"new york\",\n",
    "    \"san francisco\": \"san francisco\",\n",
    "    \"sanfrancisco\": \"san francisco\",\n",
    "}\n",
    "\n",
    "# Normalize city tokens (remove spaces)\n",
    "df12[\"city_token\"] = (\n",
    "    df12[\"city_clean_sep\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"\", regex=False)\n",
    ")\n",
    "\n",
    "# Map to canonical city names\n",
    "df12[\"city_canonical\"] = (\n",
    "    df12[\"city_token\"]\n",
    "    .map(canonical_map)\n",
    "    .fillna(df12[\"city_clean_sep\"])\n",
    ")\n",
    "\n",
    "print(df12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a0a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         raw_signup       signup_dt_raw\n",
      "0  2024-01-01 10:00 2024-01-01 10:00:00\n",
      "1  01/01/2024 15:00                 NaT\n",
      "2        2024/01/01                 NaT\n",
      "NaT count: 2\n"
     ]
    }
   ],
   "source": [
    "df12 = pd.DataFrame({\n",
    "    \"raw_signup\": [\n",
    "        \"2024-01-01 10:00\",\n",
    "        \"01/01/2024 15:00\",\n",
    "        \"2024/01/01\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# normalize separators + parse safely\n",
    "df12[\"signup_dt_raw\"] = pd.to_datetime(\n",
    "    df12[\"raw_signup\"].str.replace(\"/\", \"-\", regex=False),\n",
    "    errors=\"coerce\",\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "print(df12[[\"raw_signup\", \"signup_dt_raw\"]])\n",
    "print(\"NaT count:\", df12[\"signup_dt_raw\"].isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
